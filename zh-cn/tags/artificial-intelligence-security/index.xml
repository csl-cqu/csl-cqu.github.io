<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Artificial Intelligence Security - 标签 - 重庆大学网络安全实验室</title><link>https://csl-cqu.github.io/zh-cn/tags/artificial-intelligence-security/</link><description>Artificial Intelligence Security - 标签 - 重庆大学网络安全实验室</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Thu, 12 May 2022 09:40:28 +0800</lastBuildDate><atom:link href="https://csl-cqu.github.io/zh-cn/tags/artificial-intelligence-security/" rel="self" type="application/rss+xml"/><item><title>人工智能安全</title><link>https://csl-cqu.github.io/zh-cn/posts/artificial-intelligence-security/</link><pubDate>Thu, 12 May 2022 09:40:28 +0800</pubDate><author>作者</author><guid>https://csl-cqu.github.io/zh-cn/posts/artificial-intelligence-security/</guid><description>Introduction The past several years have witnessed the rapid development of Deep Learning technology. Various DL models today are widely adopted in many scenarios, e.g., image classification, speech recognition, language processing, robotics control. These applications significantly enhance the quality of life. However, new security threats are introduced to DNN models including backdoor attacks, adversarial attacks, model extraction attacks, privacy inference attacks, etc. It is critical to protect these DNN models</description></item></channel></rss>